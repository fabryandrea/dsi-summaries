{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "non-parametric\n",
    "1. calculate the distance from x to all points in dataset\n",
    "2. sort the points by increasing distance\n",
    "3. predict the majority label (classification) / average value (regression) of the k closest point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![test](https://qph.fs.quoracdn.net/main-qimg-32a7eff79169c81b19f548248f0962ae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* categorical variables: use one hot encoder (no need to omit one dummy)\n",
    "* standardizing/normalizing is essential (since it is distance based)\n",
    "* text data:\n",
    "* null values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tuning parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k <br>\n",
    "distance:\n",
    "* Euclidean: $\\displaystyle\\sum{(a_i-b_i)^2}$ <br>\n",
    "* Manhattan: $\\displaystyle\\sum{|a_i-b_i|}$ <br>\n",
    "* cosine: 1 - cosine similarity $\\displaystyle1-\\frac{ab}{|a||b|}$\n",
    "* Mahalobnis <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pluses / minuses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* works well for d<5 dimensions\n",
    "* few hyperparameters\n",
    "* super simple\n",
    "* can weight distances\n",
    "* can be used for classification / regression \n",
    "* prone to outliers\n",
    "* outperforms linear regression models when data does not exhibit a linear relationship\n",
    "* doesn't work well for small number of observations per predictors\n",
    "* can be used to fill in missing data (by finding k nearest neighbors based on present features and then filling in the missing value based on the average of the nearest neighbors)\n",
    "* can be used as a first classifier in a staged process (adding the result as a new feature to the record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-Nearest Neighbor\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# load iris the datasets\n",
    "dataset = datasets.load_iris()\n",
    "\n",
    "# fit a k-nearest neighbor model to the data\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(dataset.data, dataset.target)\n",
    "print(model)\n",
    "\n",
    "# make predictions\n",
    "expected = dataset.target\n",
    "predicted = model.predict(dataset.data)\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
